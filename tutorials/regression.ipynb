{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook estimates the area of squares and circles, in pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from cnn_framework.dummy_regression_cnn.data_set import DummyRegressionCnnDataSet\n",
    "from cnn_framework.dummy_regression_cnn.model_params import DummyModelParams\n",
    "from cnn_framework.dummy_regression_cnn.model import DummyCnn\n",
    "\n",
    "from cnn_framework.utils.data_loader_generators.data_loader_generator import DataLoaderGenerator\n",
    "from cnn_framework.utils.model_managers.regression_model_manager import RegressionModelManager\n",
    "from cnn_framework.utils.data_managers.default_data_manager import DefaultDataManager\n",
    "from cnn_framework.utils.metrics import MeanErrorMetric\n",
    "from cnn_framework.utils.create_dummy_data_set import generate_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model time id: 20230908-154454-local\n",
      "epochs 50 | batch 2 | lr 0.001 | weight decay 0.0 | dropout 0.0\n",
      "\n",
      "Model will be saved in C:\\Users\\thoma\\models/local/dummy_regression_cnn/20230908-154454-local\n",
      "Predictions will be saved in C:\\Users\\thoma\\predictions/local/dummy_regression_cnn/20230908-154454-local\n",
      "Tensorboard logs will be saved in C:\\Users\\thoma\\tensorboard/local/20230908-154454-local_dummy_regression_cnn\n"
     ]
    }
   ],
   "source": [
    "params = DummyModelParams()\n",
    "params.update()\n",
    "\n",
    "# Create data set if needed\n",
    "if not os.path.exists(params.data_dir):\n",
    "    generate_data_set(params.data_dir)\n",
    "    print(f\"\\nData set created in {params.data_dir}\")\n",
    "\n",
    "print(f\"\\nModel will be saved in {params.models_folder}\")\n",
    "print(f\"Predictions will be saved in {params.output_dir}\")\n",
    "print(f\"Tensorboard logs will be saved in {params.tensorboard_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data source ###\n",
      "train data is loaded from C:\\Users\\thoma\\data\\dummy - 80% elements\n",
      "val data is loaded from C:\\Users\\thoma\\data\\dummy - 10% elements\n",
      "test data is loaded from C:\\Users\\thoma\\data\\dummy - 10% elements\n",
      "###################\n",
      "train has 160 images.\n",
      "val has 20 images.\n",
      "test has 20 images.\n",
      "###################\n"
     ]
    }
   ],
   "source": [
    "loader_generator = DataLoaderGenerator(params, DummyRegressionCnnDataSet, DefaultDataManager)\n",
    "train_dl, val_dl, test_dl = loader_generator.generate_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current commit hash: 589eca1e521ba7aa867d3d42d738cdbe2fda362f\n"
     ]
    }
   ],
   "source": [
    "model = DummyCnn(\n",
    "    nb_classes=params.nb_classes,\n",
    "    nb_input_channels=params.nb_modalities * params.nb_stacks_per_modality,\n",
    ")\n",
    "\n",
    "manager = RegressionModelManager(model, params, MeanErrorMetric)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=float(params.learning_rate), betas=(params.beta1, params.beta2),\n",
    ")  # define the optimization\n",
    "\n",
    "loss_function = nn.L1Loss()  # define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress: 100.0% | Local step 80 | Epoch 50\n",
      "Best model saved at epoch 40.\n",
      "\n",
      "Training successfully finished in 0:01:20.475006.\n"
     ]
    }
   ],
   "source": [
    "manager.fit(train_dl, val_dl, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting with early stopping model.\n",
      "Model evaluation in progress: 100.0% | Batch #9\n",
      "Average MeanError: -137.99\n",
      "\n",
      "Predicting with final model.\n",
      "Model evaluation in progress: 100.0% | Batch #9\n",
      "Average MeanError: -261.53\n"
     ]
    }
   ],
   "source": [
    "for model_path, name in zip(\n",
    "    [manager.model_save_path_early_stopping, manager.model_save_path],\n",
    "    [\"early stopping\", \"final\"],\n",
    "):\n",
    "    print(f\"\\nPredicting with {name} model.\")\n",
    "    # Update model with saved one\n",
    "    manager.model.load_state_dict(torch.load(model_path))\n",
    "    manager.predict(test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
