{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pythae.pipelines import TrainingPipeline\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.trainers.training_callbacks import WandbCallback\n",
    "from pythae.models import AutoModel, BetaVAE, BetaVAEConfig\n",
    "\n",
    "from cnn_framework.dummy_vae_model.data_set import DummyVAEDataSet\n",
    "from cnn_framework.dummy_vae_model.model_params import DummyVAEModelParams\n",
    "\n",
    "from cnn_framework.dummy_vae_model.decoder import CustomDecoder\n",
    "from cnn_framework.dummy_vae_model.encoder import CustomEncoder\n",
    "\n",
    "from cnn_framework.utils.DataManagers import DefaultDataManager\n",
    "from cnn_framework.utils.data_loader_generators.DataLoaderGenerator import DataLoaderGenerator\n",
    "from cnn_framework.utils.metrics import MeanSquaredErrorMetric\n",
    "from cnn_framework.utils.model_managers.ModelManager import ModelManager\n",
    "from cnn_framework.utils.model_managers.VAEModelManager import VAEModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model time id: 20230901-105227-local\n",
      "epochs 10 | batch 2 | lr 0.0001 | weight decay 0.05 | dropout 0.0 | latent dim 16 | beta 1 | gamma 0 | delta 0 | depth 5 | kld loss standard | encoder name timm-efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "params = DummyVAEModelParams()\n",
    "params.update()\n",
    "params.data_dir = r\"C:\\Users\\thoma\\data\\Other\\square_circle_uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data source ###\n",
      "train data is loaded from C:\\Users\\thoma\\data\\Other\\square_circle_uniform - 80% elements\n",
      "val data is loaded from C:\\Users\\thoma\\data\\Other\\square_circle_uniform - 10% elements\n",
      "test data is loaded from C:\\Users\\thoma\\data\\Other\\square_circle_uniform - 10% elements\n",
      "###################\n",
      "train has 160 images.\n",
      "val has 20 images.\n",
      "test has 20 images.\n",
      "###################\n"
     ]
    }
   ],
   "source": [
    "loader_generator = DataLoaderGenerator(params, DummyVAEDataSet, DefaultDataManager)\n",
    "train_dl, val_dl, test_dl = loader_generator.generate_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in encoder: 4170844\n",
      "Number of parameters in decoder: 2498820\n",
      "Current commit hash: 9f20e1105dc4ee3322cf6902419aaf7ab72d9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthomas-bonte\u001b[0m (\u001b[33mcbio-bis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\thoma\\cnn_framework\\tutorials\\wandb\\run-20230901_105235-v3vnheu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cbio-bis/vae-dummy/runs/v3vnheu2' target=\"_blank\">20230901-105227-local</a></strong> to <a href='https://wandb.ai/cbio-bis/vae-dummy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cbio-bis/vae-dummy' target=\"_blank\">https://wandb.ai/cbio-bis/vae-dummy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cbio-bis/vae-dummy/runs/v3vnheu2' target=\"_blank\">https://wandb.ai/cbio-bis/vae-dummy/runs/v3vnheu2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create folder to save model\n",
    "os.makedirs(params.models_folder, exist_ok=True)\n",
    "\n",
    "my_training_config = BaseTrainerConfig(\n",
    "    output_dir=params.models_folder,\n",
    "    num_epochs=params.num_epochs,\n",
    "    learning_rate=params.learning_rate,\n",
    "    per_device_train_batch_size=params.batch_size,\n",
    "    per_device_eval_batch_size=params.batch_size,\n",
    "    train_dataloader_num_workers=params.num_workers,\n",
    "    eval_dataloader_num_workers=params.num_workers,\n",
    "    steps_saving=None,\n",
    "    optimizer_cls=\"AdamW\",\n",
    "    optimizer_params={\n",
    "        \"weight_decay\": params.weight_decay,\n",
    "        \"betas\": (params.beta1, params.beta2),\n",
    "    },\n",
    "    scheduler_cls=\"ReduceLROnPlateau\",\n",
    "    scheduler_params={\"patience\": 5, \"factor\": 0.5},\n",
    ")\n",
    "\n",
    "# Set up the model configuration\n",
    "my_vae_config = BetaVAEConfig(\n",
    "    reconstruction_loss=params.reconstruction_loss,\n",
    "    input_dim=(\n",
    "        params.nb_modalities * params.nb_stacks_per_modality,\n",
    "        params.input_dimensions.height,\n",
    "        params.input_dimensions.width,\n",
    "    ),\n",
    "    latent_dim=params.latent_dim,\n",
    "    beta=params.beta,\n",
    "    uses_default_decoder=False,\n",
    "    uses_default_encoder=False,\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "if params.model_pretrained_path:\n",
    "    vae_model = AutoModel.load_from_folder(params.model_pretrained_path)\n",
    "    # Update modifiable parameters\n",
    "    vae_model.model_config = my_vae_config\n",
    "    vae_model.beta = my_vae_config.beta\n",
    "else:\n",
    "    encoder = CustomEncoder(params, my_vae_config)\n",
    "    print(f\"Number of parameters in encoder: {sum(p.numel() for p in encoder.parameters())}\")\n",
    "    decoder = CustomDecoder(params, my_vae_config)\n",
    "    print(f\"Number of parameters in decoder: {sum(p.numel() for p in decoder.parameters())}\")\n",
    "    vae_model = BetaVAE(encoder=encoder, decoder=decoder, model_config=my_vae_config)\n",
    "\n",
    "# Build the Pipeline\n",
    "pipeline = TrainingPipeline(training_config=my_training_config, model=vae_model)\n",
    "\n",
    "# Compute mean_std for future normalization\n",
    "model_manager = ModelManager(vae_model, params, None)\n",
    "model_manager.compute_and_save_mean_std(train_dl, val_dl)\n",
    "\n",
    "train_dl.dataset.initialize_transforms()\n",
    "val_dl.dataset.initialize_transforms()\n",
    "\n",
    "# Create you callback\n",
    "callbacks = []  # the TrainingPipeline expects a list of callbacks\n",
    "wandb_cb = WandbCallback()  # Build the callback\n",
    "# SetUp the callback\n",
    "wandb_cb.setup(\n",
    "    training_config=my_training_config,  # training config\n",
    "    model_config=my_vae_config,  # model config\n",
    "    project_name=params.wandb_project,  # specify your wandb project\n",
    "    entity_name=params.wandb_entity,  # specify your wandb entity\n",
    "    run_name=params.format_now,  # name of the run\n",
    ")\n",
    "callbacks.append(wandb_cb)  # Add it to the callbacks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train dataset...\n",
      "Checking eval dataset...\n",
      "Using Base Trainer\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (65536) must match the size of tensor b (16384) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thoma\\cnn_framework\\tutorials\\vae.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Launch the Pipeline\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipeline(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_data\u001b[39m=\u001b[39;49mtrain_dl\u001b[39m.\u001b[39;49mdataset,  \u001b[39m# must be torch.Tensor, np.array or torch datasets\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     eval_data\u001b[39m=\u001b[39;49mval_dl\u001b[39m.\u001b[39;49mdataset,  \u001b[39m# must be torch.Tensor, np.array or torch datasets\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoma/cnn_framework/tutorials/vae.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\benchmark_VAE\\src\\pythae\\pipelines\\training.py:235\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[1;34m(self, train_data, eval_data, callbacks)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_config, BaseTrainerConfig):\n\u001b[0;32m    234\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mUsing Base Trainer\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 235\u001b[0m     trainer \u001b[39m=\u001b[39m BaseTrainer(\n\u001b[0;32m    236\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[0;32m    237\u001b[0m         train_dataset\u001b[39m=\u001b[39;49mtrain_dataset,\n\u001b[0;32m    238\u001b[0m         eval_dataset\u001b[39m=\u001b[39;49meval_dataset,\n\u001b[0;32m    239\u001b[0m         training_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_config,\n\u001b[0;32m    240\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[0;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe provided training config is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\benchmark_VAE\\src\\pythae\\trainers\\base_trainer\\base_trainer.py:139\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, model, train_dataset, eval_dataset, training_config, callbacks)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m    138\u001b[0m \u001b[39m# run sanity check on the model\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_model_sanity_check(model, train_loader)\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_main_process:\n\u001b[0;32m    142\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mModel passed sanity check !\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mReady for training.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\benchmark_VAE\\src\\pythae\\trainers\\base_trainer\\base_trainer.py:313\u001b[0m, in \u001b[0;36mBaseTrainer._run_model_sanity_check\u001b[1;34m(self, model, loader)\u001b[0m\n\u001b[0;32m    311\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(loader))\n\u001b[0;32m    312\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_inputs_to_device(inputs)\n\u001b[1;32m--> 313\u001b[0m model(train_dataset)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\benchmark_VAE\\src\\pythae\\models\\beta_vae\\beta_vae_model.py:71\u001b[0m, in \u001b[0;36mBetaVAE.forward\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m z, eps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_gauss(mu, std)\n\u001b[0;32m     69\u001b[0m recon_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z)[\u001b[39m\"\u001b[39m\u001b[39mreconstruction\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 71\u001b[0m loss, recon_loss, kld \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_function(recon_x, x, mu, log_var, z)\n\u001b[0;32m     73\u001b[0m output \u001b[39m=\u001b[39m ModelOutput(\n\u001b[0;32m     74\u001b[0m     recon_loss\u001b[39m=\u001b[39mrecon_loss,\n\u001b[0;32m     75\u001b[0m     reg_loss\u001b[39m=\u001b[39mkld,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     z\u001b[39m=\u001b[39mz,\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\benchmark_VAE\\src\\pythae\\models\\beta_vae\\beta_vae_model.py:87\u001b[0m, in \u001b[0;36mBetaVAE.loss_function\u001b[1;34m(self, recon_x, x, mu, log_var, z)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_function\u001b[39m(\u001b[39mself\u001b[39m, recon_x, x, mu, log_var, z):\n\u001b[0;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39mreconstruction_loss \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m         recon_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmse_loss(\n\u001b[0;32m     88\u001b[0m             recon_x\u001b[39m.\u001b[39;49mreshape(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     89\u001b[0m             x\u001b[39m.\u001b[39;49mreshape(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     90\u001b[0m             reduction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     91\u001b[0m         )\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     93\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39mreconstruction_loss \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbce\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     95\u001b[0m         recon_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(\n\u001b[0;32m     96\u001b[0m             recon_x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     97\u001b[0m             x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     98\u001b[0m             reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m         )\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\nn\\functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3276\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3277\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3280\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\thoma\\anaconda3\\envs\\pytorch-env2\\lib\\site-packages\\torch\\functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (65536) must match the size of tensor b (16384) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Launch the Pipeline\n",
    "pipeline(\n",
    "    train_data=train_dl.dataset,  # must be torch.Tensor, np.array or torch datasets\n",
    "    eval_data=val_dl.dataset,  # must be torch.Tensor, np.array or torch datasets\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current commit hash: 71c7abb786f18a1e1a25ffc70c3793c067183938\n",
      "Model evaluation in progress: 100.0% | Batch #9\n",
      "Average MeanSquaredError: -0.23\n"
     ]
    }
   ],
   "source": [
    "# Test and save images\n",
    "manager = VAEModelManager(vae_model, params, MeanSquaredErrorMetric)\n",
    "manager.predict(test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
