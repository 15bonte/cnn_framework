{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook predicts the binary mask of squares/circles from RGB images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "\n",
        "from cnn_framework.dummy_segmentation.data_set import DummyDataSet\n",
        "from cnn_framework.dummy_segmentation.model_params import DummyModelParams\n",
        "from cnn_framework.dummy_segmentation.model import UNet\n",
        "\n",
        "from cnn_framework.utils.data_loader_generators.data_loader_generator import DataLoaderGenerator\n",
        "from cnn_framework.utils.model_managers.model_manager import ModelManager\n",
        "from cnn_framework.utils.data_managers.default_data_manager import DefaultDataManager\n",
        "from cnn_framework.utils.metrics import PCC\n",
        "from cnn_framework.utils.create_dummy_data_set import generate_data_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model time id: 20230904-104106-local\n",
            "epochs 50 | batch 2 | lr 0.0001 | weight decay 0.0 | dropout 0.0\n",
            "\n",
            "Model will be saved in C:\\Users\\thoma\\models\\local/dummy_segmentation/20230904-104106-local\n",
            "Predictions will be saved in C:\\Users\\thoma\\predictions\\local/dummy_segmentation/20230904-104106-local\n",
            "Tensorboard logs will be saved in C:\\Users\\thoma\\tensorboard\\local/20230904-104106-local_dummy_segmentation\n"
          ]
        }
      ],
      "source": [
        "params = DummyModelParams()\n",
        "params.update()\n",
        "\n",
        "# Create data set if needed\n",
        "if not os.path.exists(params.data_dir):\n",
        "    generate_data_set(params.data_dir)\n",
        "    print(f\"\\nData set created in {params.data_dir}\")\n",
        "\n",
        "print(f\"\\nModel will be saved in {params.models_folder}\")\n",
        "print(f\"Predictions will be saved in {params.output_dir}\")\n",
        "print(f\"Tensorboard logs will be saved in {params.tensorboard_folder_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Data source ###\n",
            "train data is loaded from C:\\Users\\thoma\\data\\dummy - 80% elements\n",
            "val data is loaded from C:\\Users\\thoma\\data\\dummy - 10% elements\n",
            "test data is loaded from C:\\Users\\thoma\\data\\dummy - 10% elements\n",
            "###################\n",
            "train has 160 images.\n",
            "val has 20 images.\n",
            "test has 20 images.\n",
            "###################\n"
          ]
        }
      ],
      "source": [
        "loader_generator = DataLoaderGenerator(params, DummyDataSet, DefaultDataManager)\n",
        "train_dl, val_dl, test_dl = loader_generator.generate_data_loader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current commit hash: 8fb09e49bd9849a488b1c0871e163fc6c713b2f7\n"
          ]
        }
      ],
      "source": [
        "model = UNet(\n",
        "    nb_classes=params.out_channels,\n",
        "    nb_input_channels=params.nb_modalities * params.nb_stacks_per_modality,\n",
        ")\n",
        "manager = ModelManager(model, params, PCC)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=float(params.learning_rate),\n",
        "    betas=(params.beta1, params.beta2),\n",
        ")  # define the optimization\n",
        "loss_function = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training in progress: 100.0% | Local step 79 | Epoch 49\n",
            "Best model saved at epoch 47.\n",
            "\n",
            "Training successfully finished in 0:01:51.580172.\n"
          ]
        }
      ],
      "source": [
        "manager.fit(train_dl, val_dl, optimizer, loss_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model evaluation in progress: 100.0% | Batch #9\n",
            "Average PCC: 1.0\n"
          ]
        }
      ],
      "source": [
        "manager.predict(test_dl)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-env2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
